# -*- coding: UTF-8 -*-
from contextlib import contextmanager
from copy import copy, deepcopy
from datetime import datetime, timezone
from functools import partial
from io import StringIO
from itertools import islice
from operator import delitem, setitem
from re import compile
from threading import RLock
from types import EllipsisType
from typing import (
    Any,
    Iterator,
    Mapping,
    MutableMapping,
    MutableSequence,
    Sequence,
    TypeVar,
    TypedDict,
    overload,
)

from ._util import (
    SupportsWrite,
    Transaction,
    getitem_or_def,
    int_or_def,
    iter_or_def,
    str_or_repr,
)
from .types import (
    ID,
    URLID,
    Timestamp,
    URLID_gen,
    URLStr,
    URLStr_,
    Word,
    WordFrequency,
    WordID,
    WordID_gen,
    WordPosition,
)

_T = TypeVar("_T")
_U = TypeVar("_U")
_WORD_REGEX = compile(r"[a-zA-Z0-9\-_]+")


class Scheme:
    """
    Database scheme. `Root` is the root scheme. The scheme is compatible with JSON.

    Do not modify the database fields directly. Instead, go through the methods of this class. This enforces database constraints.
    """

    __slots__ = ("_database", "_lock")

    class Root(TypedDict):
        """
        Database root scheme.
        """

        url_ids: Mapping[URLStr_, URLID]
        """
        Mapping from URLs to URL IDs.

        Constraints: `urls` is the exact inverse of `url_ids`. Every valid key of `url_ids` is a valid first key of `forward_index`.
        """
        word_ids: Mapping[Word, WordID]
        """
        Mapping from words to word IDs.

        Constraints: `words` is the exact inverse of `word_ids`. Every valid key of `word_ids` is a valid first key of `inverted_index`.
        """

        pages: Mapping[URLID, "Scheme.Page"]
        """
        Page metadata.

        Constraints: Not every valid key of `url_ids` need to have a `Page`.
        """

        inverted_index: Mapping[WordID, Mapping[URLID, Sequence[WordPosition]]]
        """
        Mapping from a word and a URL to the locations of the word in the page for the URL.

        Constraints: Every valid first key of `inverted_index` is a valid key of `word_ids`. Every valid key tuple `(word_id, url_id)` has a nonempty position sequence. Position sequences are sorted and do not contain duplicates.
        """

        # autogenerated data

        forward_index: Mapping[URLID, Mapping[WordID, WordFrequency]]
        """
        Mapping from a URL and a word to the number of occurrence of the word in the page for the URL.

        This field is autogenerated from `inverted_index`.

        Constraints: Every valid first key of `forward_index` is a valid key of `url_ids`. For each valid key tuple `(word_id, url_id)` of `inverted_index`, `(url_id, word_id)` is a valid key tuple of `forward_index`.
        """

        urls: Mapping[URLID, URLStr_]
        """
        Mapping from URL IDs to URLs.

        This field is autogenerated from `url_ids`.

        Constraints: `url_ids` is the exact inverse of `urls`.
        """
        words: Mapping[WordID, Word]
        """
        Mapping from word IDs to words.

        This field is autogenerated from `word_ids`.

        Constraints: `word_ids` is the exact inverse of `words`.
        """

    class Page(TypedDict):
        """
        Database page scheme.
        """

        title: str
        """
        Page title.
        """
        text: str
        """
        Page content in plaintext. That is, without any markups.
        """
        links: Sequence[URLStr_]
        """
        Links in the page.
        """
        mod_time: Timestamp | None
        """
        Last modification time.
        """

    @classmethod
    def init(cls, obj: object) -> Root:
        """
        Initialize a database conforming to the scheme from an object. Only valid data are kept.
        """

        ret = cls.Root(
            {
                "url_ids": {},
                "word_ids": {},
                "pages": {},
                "inverted_index": {},
                "forward_index": {},
                "urls": {},
                "words": {},
            }
        )

        # initialize `url_ids` and `urls`; partially initialize `forward_index`
        cur_obj = getitem_or_def(obj, "url_ids")
        cur_IDs = set[URLID]()
        for key in iter_or_def(cur_obj):
            if (val := getitem_or_def(cur_obj, key)) is ... or (
                val := int_or_def(val)
            ) is ...:
                continue
            key, val = URLStr(str_or_repr(key)), URLID(ID(val))
            if key in ret["url_ids"]:
                continue
            while val in cur_IDs:
                val = URLID_gen()
            cur_IDs.add(val)
            cls._modify(ret["url_ids"])[key] = val
            cls._modify(ret["urls"])[val] = key
            cls._modify(ret["forward_index"])[val] = {}

        # initialize `word_ids` and `words`; partially initialize `inverted_index`
        cur_obj = getitem_or_def(obj, "word_ids")
        cur_IDs = set[WordID]()
        for key in iter_or_def(cur_obj):
            if (val := getitem_or_def(cur_obj, key)) is ... or (
                val := int_or_def(val)
            ) is ...:
                continue
            key, val = Word(str_or_repr(key)), WordID(ID(val))
            while val in cur_IDs:
                val = WordID_gen()
            cur_IDs.add(val)
            cls._modify(ret["word_ids"])[key] = val
            cls._modify(ret["words"])[val] = key
            cls._modify(ret["inverted_index"])[val] = {}

        # initialize `pages`
        def fix_page(obj: object) -> Scheme.Page | EllipsisType:
            if (cur_obj := getitem_or_def(obj, "text")) is ...:
                return ...
            text = str_or_repr(cur_obj)

            mod_time = int_or_def(getitem_or_def(obj, "mod_time"))
            mod_time = None if mod_time is ... else Timestamp(mod_time)

            return cls.Page(
                {
                    "title": str_or_repr(getitem_or_def(obj, "title", "")),
                    "text": text,
                    "links": list(
                        map(
                            URLStr,
                            map(str_or_repr, iter_or_def(getitem_or_def(obj, "links"))),
                        )
                    ),
                    "mod_time": mod_time,
                }
            )

        def fix_key_as_url_id(key: object) -> URLID | EllipsisType:
            try:
                return URLID(ID(int(str_or_repr(key))))
            except (TypeError, ValueError):
                try:
                    return ret["url_ids"][URLStr(str_or_repr(key))]
                except KeyError:
                    return ...

        def fix_key_as_word_id(key: object) -> WordID | EllipsisType:
            try:
                return WordID(ID(int(str_or_repr(key))))
            except (TypeError, ValueError):
                try:
                    return ret["word_ids"][Word(str_or_repr(key))]
                except KeyError:
                    return ...

        cur_obj = getitem_or_def(obj, "pages")
        for key in iter_or_def(cur_obj):
            key0 = key
            if (key := fix_key_as_url_id(key)) is ... or key not in ret["urls"]:
                continue
            if (val := getitem_or_def(cur_obj, key0)) is ... or (
                val := fix_page(val)
            ) is ...:
                continue
            cls._modify(ret["pages"])[key] = val

        # initialize `inverted_index` and `forward_index`
        cur_obj = getitem_or_def(obj, "inverted_index")
        for key_word_id in iter_or_def(cur_obj):
            key_word_id0 = key_word_id
            if (
                key_word_id := fix_key_as_word_id(key_word_id)
            ) is ... or key_word_id not in ret["words"]:
                continue
            if (val_word_id := getitem_or_def(cur_obj, key_word_id0)) is ...:
                continue
            inverted_index_word = ret["inverted_index"][key_word_id]
            for key_url_id in iter_or_def(val_word_id):
                key_url_id0 = key_url_id
                if (
                    key_url_id := fix_key_as_url_id(key_url_id)
                ) is ... or key_url_id not in ret["urls"]:
                    continue
                if (val_url_id := getitem_or_def(val_word_id, key_url_id0)) is ...:
                    continue
                inverted_index_word_URL = sorted(
                    set(
                        WordPosition(pos)
                        for pos in map(
                            int_or_def, map(str_or_repr, iter_or_def(val_url_id))
                        )
                        if isinstance(pos, int) and pos >= 0
                    )
                )
                if not inverted_index_word_URL:
                    continue
                cls._modify(inverted_index_word)[key_url_id] = inverted_index_word_URL
                cls._modify(ret["forward_index"][key_url_id])[key_word_id] = (
                    WordFrequency(len(inverted_index_word_URL))
                )

        return ret

    def __init__(self, database: Root) -> None:
        """
        Manage a database using this scheme.
        """
        self._lock = RLock()
        self._database = database

    @contextmanager
    def lock(self) -> Iterator[Root]:
        """
        Lock the database.
        """
        with self._lock:
            yield self._database

    def url_id(self, _x: URLStr_, /, transaction: Transaction | None = None) -> URLID:
        """
        Get the URL ID for a url. Assigns a new ID if not already assigned.
        """
        x_ids = self._database["url_ids"]
        with self._lock:
            try:
                return x_ids[_x]
            except KeyError:
                urls, forward_index = (
                    self._database["urls"],
                    self._database["forward_index"],
                )
                with Transaction(transaction) as trans:
                    id = self._modify(x_ids)[_x] = URLID_gen()
                    trans.push(partial(delitem, self._modify(x_ids), _x))
                    self._modify(urls)[id] = _x
                    trans.push(partial(delitem, self._modify(urls), id))
                    self._modify(forward_index)[id] = {}
                    trans.push(partial(delitem, self._modify(forward_index), id))
                return id

    def word_id(self, _x: Word, /, transaction: Transaction | None = None) -> WordID:
        """
        Get the URL ID for a word. Assigns a new ID if not already assigned.
        """
        x_ids = self._database["word_ids"]
        with self._lock:
            try:
                return x_ids[_x]
            except KeyError:
                words, inverted_index = (
                    self._database["words"],
                    self._database["inverted_index"],
                )
                with Transaction(transaction) as trans:
                    id = self._modify(x_ids)[_x] = WordID_gen()
                    trans.push(partial(delitem, self._modify(x_ids), _x))
                    self._modify(words)[id] = _x
                    trans.push(partial(delitem, self._modify(words), id))
                    self._modify(inverted_index)[id] = {}
                    trans.push(partial(delitem, self._modify(inverted_index), id))
                return id

    def index_page(
        self, url_id: URLID, page: Page, /, transaction: Transaction | None = None
    ) -> bool:
        """
        Index an page and return whether the page is actually indexed. Raises `ValueError` if `url_id` is invalid.
        """
        urls, pages, forward_index, inverted_index = (
            self._database["urls"],
            self._database["pages"],
            self._database["forward_index"],
            self._database["inverted_index"],
        )
        with self._lock:
            if url_id not in urls:
                raise ValueError(f"URL ID not found: {url_id}")
            with Transaction(transaction) as trans:
                try:
                    db_page = pages[url_id]
                except KeyError:
                    db_page = self._modify(pages)[url_id] = self.Page(
                        {
                            "title": "",
                            "text": "",
                            "links": [],
                            "mod_time": None,
                        }
                    )
                    trans.push(partial(delitem, self._modify(pages), url_id))

                if (
                    page["mod_time"] is not None
                    and db_page["mod_time"] is not None
                    and page["mod_time"] <= db_page["mod_time"]
                ):
                    return False

                old_page = copy(db_page)
                db_page.update(deepcopy(page))
                trans.push(partial(db_page.update, old_page))

                # clear forward index and inverted index
                forward_index_page = forward_index[url_id]
                old_forward_index_page = copy(forward_index_page)
                self._modify(forward_index_page).clear()
                trans.push(
                    partial(
                        self._modify(forward_index_page).update, old_forward_index_page
                    )
                )
                for word_id in old_forward_index_page:
                    word_positions = self._modify(inverted_index[word_id])[url_id]
                    del self._modify(inverted_index[word_id])[url_id]
                    trans.push(
                        partial(
                            setitem,
                            self._modify(inverted_index[word_id]),
                            url_id,
                            word_positions,
                        )
                    )

                for word_match in _WORD_REGEX.finditer(db_page["text"]):
                    word, position = Word(word_match[0]), WordPosition(
                        word_match.start()
                    )
                    word_id = self.word_id(word, transaction=transaction)

                    try:
                        word_frequency = forward_index_page[word_id]
                    except KeyError:
                        word_frequency = self._modify(forward_index_page)[word_id] = (
                            WordFrequency(0)
                        )
                        trans.push(
                            partial(delitem, self._modify(forward_index_page), word_id)
                        )
                    self._modify(forward_index_page)[word_id] = WordFrequency(
                        word_frequency + 1
                    )
                    trans.push(
                        partial(
                            setitem,
                            self._modify(forward_index_page),
                            word_id,
                            word_frequency,
                        )
                    )

                    try:
                        word_positions = inverted_index[word_id][url_id]
                    except KeyError:
                        word_positions = self._modify(inverted_index[word_id])[
                            url_id
                        ] = []
                        trans.push(
                            partial(
                                delitem, self._modify(inverted_index[word_id]), url_id
                            )
                        )
                    self._modify(word_positions).append(position)
                    trans.push(self._modify(word_positions).pop)
        return True

    def summary(
        self,
        fp: SupportsWrite[str],
        *,
        count: int | None = None,
        keyword_count: int | None = 10,
        link_count: int | None = 10,
    ) -> None:
        """
        Write a summary of the database to `fp`.

        `count` is the number of results to return. `None` means all results.
        `keyword_count` is the number of keywords, most frequent first, per result. `None` means all keywords.
        `link_count` is the number of links, ordered alphabetically, per result. `None` means all links.
        """
        with self._lock:
            separator = ""
            for url_id, page in islice(self._database["pages"].items(), count):
                fp.write(separator)
                separator = f"{'-' * 100}\n"

                fp.write(f"{page['title'] or '(no title)'}\n")
                fp.write(f"{self._database['urls'][url_id]}\n")
                fp.write(
                    f"{datetime.fromtimestamp(page['mod_time'], timezone.utc).isoformat() if page['mod_time'] else '(no last modification time)'}, {len(page['text'])}\n"
                )

                fp.write(
                    f"""{'; '.join(f'{self._database["words"][word_id]} {word_frequency}' for word_id, word_frequency in islice(
                    sorted(
                        self._database['forward_index'][url_id].items(),
                        key=lambda item: item[1],
                        reverse=True,
                    ),
                    keyword_count,
                ))}\n"""
                )

                fp.write(
                    "".join(
                        f"{link}\n"
                        for link in islice(sorted(page["links"]), link_count)
                    )
                )

    def summary_s(self, *args: Any, **kwargs: Any) -> str:
        """
        Same as `summary`, except that it returns a string. Same options are supported.
        """
        io = StringIO()
        self.summary(io, *args, **kwargs)
        return io.getvalue()

    @overload
    @classmethod
    def _modify(cls, obj: Mapping[_T, _U]) -> MutableMapping[_T, _U]: ...

    @overload
    @classmethod
    def _modify(cls, obj: Sequence[_T]) -> MutableSequence[_T]: ...

    @classmethod
    def _modify(cls, obj: object) -> object:
        if not any(isinstance(obj, valid_cls) for valid_cls in (dict, list)):
            raise ValueError(f"Object is not modifiable: {obj}")
        return obj
